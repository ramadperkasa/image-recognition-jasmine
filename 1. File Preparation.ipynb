{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kita Pisahkan datanya menjadi 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Url Source : https://www.kaggle.com/alxmamaev/flowers-recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train (data latih)\n",
    "- validation (validasi untuk data latih)\n",
    "- test (data testing untuk menguji model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T13:36:44.577679Z",
     "start_time": "2020-04-27T13:36:44.576110Z"
    }
   },
   "outputs": [],
   "source": [
    "# extract melalui notebook jika diperlukan\n",
    "# !unzip flowers-recognition.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T13:20:25.152791Z",
     "start_time": "2020-04-27T13:20:25.151197Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T13:20:25.411819Z",
     "start_time": "2020-04-27T13:20:25.410118Z"
    }
   },
   "outputs": [],
   "source": [
    "mypath= './Jasmine/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T13:20:26.610071Z",
     "start_time": "2020-04-27T13:20:26.587117Z"
    }
   },
   "outputs": [],
   "source": [
    "file_name = []\n",
    "tag = []\n",
    "full_path = []\n",
    "for path, subdirs, files in os.walk(mypath):\n",
    "    for name in files:\n",
    "        full_path.append(os.path.join(path, name).replace(\"\\\\\",\"/\")) \n",
    "        tag.append(path.split('/')[-1])        \n",
    "        file_name.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T13:24:26.890142Z",
     "start_time": "2020-04-27T13:24:26.883846Z"
    }
   },
   "outputs": [],
   "source": [
    "# memasukan variabel yang sudah dikumpulkan pada looping di atas menjadi sebuah dataframe agar rapih\n",
    "df = pd.DataFrame({\"path\":full_path,'file_name':file_name,\"tag\":tag})\n",
    "df.groupby(['tag']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T13:24:27.173074Z",
     "start_time": "2020-04-27T13:24:27.167878Z"
    }
   },
   "outputs": [],
   "source": [
    "#cek sample datanya\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T13:24:27.608099Z",
     "start_time": "2020-04-27T13:24:27.606378Z"
    }
   },
   "outputs": [],
   "source": [
    "#load library untuk train test split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T13:24:38.449924Z",
     "start_time": "2020-04-27T13:24:38.447907Z"
    }
   },
   "outputs": [],
   "source": [
    "#variabel yang digunakan pada pemisahan data ini\n",
    "X= df['path']\n",
    "y= df['tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T13:24:38.787271Z",
     "start_time": "2020-04-27T13:24:38.781487Z"
    }
   },
   "outputs": [],
   "source": [
    "# split dataset awal menjadi data train dan test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T13:24:38.946665Z",
     "start_time": "2020-04-27T13:24:38.942709Z"
    }
   },
   "outputs": [],
   "source": [
    "# kemudian data test dibagi menjadi 2 sehingga menjadi data test dan data validation.\n",
    "X_test, X_val, y_test, y_val = train_test_split(\n",
    "    X_test, y_test, test_size=0.5, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T13:27:35.790033Z",
     "start_time": "2020-04-27T13:27:35.784677Z"
    }
   },
   "outputs": [],
   "source": [
    "# menyatukan kedalam masing-masing dataframe\n",
    "\n",
    "df_tr = pd.DataFrame({'path':X_train\n",
    "              ,'tag':y_train\n",
    "             ,'set':'train'})\n",
    "\n",
    "df_te = pd.DataFrame({'path':X_test\n",
    "              ,'tag':y_test\n",
    "             ,'set':'test'})\n",
    "\n",
    "df_val = pd.DataFrame({'path':X_val\n",
    "              ,'tag':y_val\n",
    "             ,'set':'validation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T13:27:36.006934Z",
     "start_time": "2020-04-27T13:27:36.004779Z"
    }
   },
   "outputs": [],
   "source": [
    "print('train size', len(df_tr))\n",
    "print('val size', len(df_te))\n",
    "print('test size', len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T13:45:04.988035Z",
     "start_time": "2020-04-27T13:45:04.977060Z"
    }
   },
   "outputs": [],
   "source": [
    "# melihat proporsi pada masing masing set apakah sudah ok atau masih ada yang ingin diubah\n",
    "df_all = df_tr.append([df_te,df_val]).reset_index(drop=1)\n",
    "\n",
    "print('===================================================== \\n')\n",
    "print(df_all.groupby(['set','tag']).size(),'\\n')\n",
    "\n",
    "print('===================================================== \\n')\n",
    "\n",
    "#cek sample datanya\n",
    "df_all.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merapihkan ke folder set masing-masing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T13:45:15.341975Z",
     "start_time": "2020-04-27T13:45:15.340307Z"
    }
   },
   "outputs": [],
   "source": [
    "# menghapus folder dataset jika diperlukan\n",
    "#!rm -rf dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T13:45:15.523556Z",
     "start_time": "2020-04-27T13:45:15.521907Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from tqdm.notebook import tqdm as tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T13:45:17.315452Z",
     "start_time": "2020-04-27T13:45:17.313905Z"
    }
   },
   "outputs": [],
   "source": [
    "datasource_path = \"flowers/\"\n",
    "dataset_path = \"dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T13:45:21.624008Z",
     "start_time": "2020-04-27T13:45:20.037843Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, row in tq(df_all.iterrows(), ):\n",
    "    \n",
    "    #detect filepath\n",
    "    file_path = row['path']\n",
    "    if os.path.exists(file_path) == False:\n",
    "            file_path = os.path.join(datasource_path,row['tag'],row['image'].split('.')[0])            \n",
    "    \n",
    "    #make folder destination dirs\n",
    "    if os.path.exists(os.path.join(dataset_path,row['set'],row['tag'])) == False:\n",
    "        os.makedirs(os.path.join(dataset_path,row['set'],row['tag']))\n",
    "    \n",
    "    #define file dest\n",
    "    destination_file_name = file_path.split('/')[-1]\n",
    "    file_dest = os.path.join(dataset_path,row['set'],row['tag'],destination_file_name)\n",
    "    \n",
    "    #copy file from source to dest\n",
    "    if os.path.exists(file_dest) == False:\n",
    "        shutil.copy2(file_path,file_dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membuat Classifier nya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T23:07:41.569964Z",
     "start_time": "2020-04-27T23:07:29.039041Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T00:15:16.601007Z",
     "start_time": "2020-04-28T00:15:16.598774Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Input Parameters\n",
    "dim = (160, 160)\n",
    "# dim = (456, 456)\n",
    "channel = (3, )\n",
    "input_shape = dim + channel\n",
    "\n",
    "#batch size\n",
    "batch_size = 16\n",
    "\n",
    "#Epoch\n",
    "epoch = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membuat dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T23:07:41.609100Z",
     "start_time": "2020-04-27T23:07:41.582485Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mendefinisikan Data Generatornya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T23:07:41.619545Z",
     "start_time": "2020-04-27T23:07:41.614388Z"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                 shear_range=0.2,\n",
    "                                 zoom_range=0.2,\n",
    "                                 horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mendefinisikan asal folder sumber file berasal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T03:55:43.409949Z",
     "start_time": "2020-04-28T03:55:43.090028Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# binary = [1,0,0,0,0] [0,1,0,0,0] [0,0,1,0,0] [0,0,0,1,0] [0,0,0,0,1]\n",
    "# categorical = 1,2,3,4,5\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('dataset/train/',\n",
    "                                                    target_size=dim,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory('dataset/validation/',\n",
    "                                                target_size=dim,\n",
    "                                                batch_size=batch_size,\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory('dataset/test/',\n",
    "                                                  target_size=dim,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=True)\n",
    "\n",
    "num_class = test_generator.num_classes\n",
    "labels = train_generator.class_indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T03:55:48.345523Z",
     "start_time": "2020-04-28T03:55:48.343497Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membuat tf.data untuk kompabilitas yang lebih baik untuk tensorflow 2.1 (tf.keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T23:07:42.164380Z",
     "start_time": "2020-04-27T23:07:42.161649Z"
    }
   },
   "outputs": [],
   "source": [
    "def tf_data_generator(generator, input_shape):\n",
    "    num_class = generator.num_classes\n",
    "    tf_generator = tf.data.Dataset.from_generator(\n",
    "        lambda: generator,\n",
    "        output_types=(tf.float32, tf.float32),\n",
    "        output_shapes=([None\n",
    "                        , input_shape[0]\n",
    "                        , input_shape[1]\n",
    "                        , input_shape[2]]\n",
    "                       ,[None, num_class])\n",
    "    )\n",
    "    return tf_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T23:07:42.240950Z",
     "start_time": "2020-04-27T23:07:42.168871Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = tf_data_generator(train_generator, input_shape)\n",
    "test_data = tf_data_generator(test_generator, input_shape)\n",
    "val_data = tf_data_generator(val_generator, input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membuat Struktur CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manualy define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T01:02:52.135221Z",
     "start_time": "2020-04-05T01:02:52.132534Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T01:02:53.626958Z",
     "start_time": "2020-04-05T01:02:53.225773Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128, (3, 3), padding='same', input_shape=input_shape))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_class))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile the model\n",
    "print('Compiling Model.......')\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T01:02:53.916849Z",
     "start_time": "2020-04-05T01:02:53.915340Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pre-trained model / Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Base Model (MobileNetV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T00:15:21.324641Z",
     "start_time": "2020-04-28T00:15:19.861604Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# get base models\n",
    "base_model = MobileNetV2(\n",
    "    input_shape= input_shape,\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    classes=num_class,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add top layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T00:15:22.439171Z",
     "start_time": "2020-04-28T00:15:22.437438Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers,Sequential\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T00:15:34.516170Z",
     "start_time": "2020-04-28T00:15:34.476569Z"
    }
   },
   "outputs": [],
   "source": [
    "#Adding custom layers\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(1024, activation=\"relu\")(x)\n",
    "\n",
    "predictions = layers.Dense(num_class, activation=\"softmax\")(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T00:15:35.928198Z",
     "start_time": "2020-04-28T00:15:35.905552Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T00:15:39.773224Z",
     "start_time": "2020-04-28T00:15:39.741303Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "print('Compiling Model.......')\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effinet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T00:46:28.470103Z",
     "start_time": "2020-04-05T00:46:28.468004Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -U --pre efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T00:06:42.639757Z",
     "start_time": "2020-04-28T00:06:41.172821Z"
    }
   },
   "outputs": [],
   "source": [
    "from efficientnet.tfkeras import EfficientNetB1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T00:06:45.748689Z",
     "start_time": "2020-04-28T00:06:43.400861Z"
    }
   },
   "outputs": [],
   "source": [
    "# get base models\n",
    "base_model = EfficientNetB1(\n",
    "    input_shape=input_shape,\n",
    "    include_top=False,\n",
    "    weights='noisy-student',\n",
    "    classes=num_class,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add top network layer to models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T00:06:49.522922Z",
     "start_time": "2020-04-28T00:06:49.521182Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers,Sequential\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T00:06:50.134891Z",
     "start_time": "2020-04-28T00:06:50.083642Z"
    }
   },
   "outputs": [],
   "source": [
    "#Adding custom layers\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(1024, activation=\"relu\")(x)\n",
    "\n",
    "predictions = layers.Dense(num_class, activation=\"softmax\")(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T00:06:50.996500Z",
     "start_time": "2020-04-28T00:06:50.950395Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T00:06:52.601344Z",
     "start_time": "2020-04-28T00:06:52.558985Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "print('Compiling Model.......')\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize The final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T00:06:55.440845Z",
     "start_time": "2020-04-28T00:06:55.439197Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T00:06:58.089548Z",
     "start_time": "2020-04-28T00:06:56.350302Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_viz = tf.keras.utils.plot_model(model,\n",
    "                          to_file='model.png',\n",
    "                          show_shapes=True,\n",
    "                          show_layer_names=True,\n",
    "                          rankdir='TB',\n",
    "                          expand_nested=True,\n",
    "                          dpi=55)\n",
    "model_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T04:27:13.684881Z",
     "start_time": "2020-04-28T04:27:13.683143Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCH = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T04:43:10.762055Z",
     "start_time": "2020-04-28T04:27:14.129033Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(x=train_data,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=EPOCH,\n",
    "        validation_data=val_data,\n",
    "        validation_steps=len(val_generator), \n",
    "        shuffle=True,\n",
    "        verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T04:49:58.925288Z",
     "start_time": "2020-04-28T04:49:58.922875Z"
    }
   },
   "outputs": [],
   "source": [
    "history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T04:49:59.293485Z",
     "start_time": "2020-04-28T04:49:59.291038Z"
    }
   },
   "outputs": [],
   "source": [
    "history.history['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T04:50:02.171980Z",
     "start_time": "2020-04-28T04:50:02.170248Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T04:50:02.464233Z",
     "start_time": "2020-04-28T04:50:02.361846Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot history: MAE\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T04:50:03.056913Z",
     "start_time": "2020-04-28T04:50:02.958192Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot history: MSE\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T04:50:05.626011Z",
     "start_time": "2020-04-28T04:50:05.624348Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T04:50:15.324841Z",
     "start_time": "2020-04-28T04:50:15.176405Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_BASE_PATH = \"model\"\n",
    "PROJECT_NAME = \"medium_project\"\n",
    "SAVE_MODEL_NAME = \"model.h5\"\n",
    "save_model_path = os.path.join(MODEL_BASE_PATH, PROJECT_NAME, SAVE_MODEL_NAME)\n",
    "\n",
    "if os.path.exists(os.path.join(MODEL_BASE_PATH, PROJECT_NAME)) == False:\n",
    "    os.makedirs(os.path.join(MODEL_BASE_PATH, PROJECT_NAME))\n",
    "    \n",
    "print('Saving Model At {}...'.format(save_model_path))\n",
    "model.save(save_model_path,include_optimizer=False)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T01:13:52.722441Z",
     "start_time": "2020-04-28T01:13:40.664164Z"
    }
   },
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(train_data, steps=len(train_generator), verbose=0)\n",
    "print('Accuracy on training data: {:.4f} \\nLoss on training data: {:.4f}'.format(acc,loss),'\\n')\n",
    " \n",
    "loss, acc = model.evaluate(test_data, steps=len(test_generator), verbose=0)\n",
    "print('Accuracy on test data: {:.4f} \\nLoss on test data: {:.4f}'.format(acc,loss),'\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defiine params and lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T05:29:11.481339Z",
     "start_time": "2020-04-28T05:29:11.338446Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T05:29:11.622498Z",
     "start_time": "2020-04-28T05:29:11.619866Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "input_size = (160,160)\n",
    "\n",
    "#define input shape\n",
    "channel = (3,)\n",
    "input_shape = input_size + channel\n",
    "\n",
    "#define labels\n",
    "labels = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define preprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T05:29:12.252129Z",
     "start_time": "2020-04-28T05:29:12.249482Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(img,input_size):\n",
    "    nimg = img.convert('RGB').resize(input_size, resample= 0)\n",
    "    img_arr = (np.array(nimg))/255\n",
    "    return img_arr\n",
    "\n",
    "def reshape(imgs_arr):\n",
    "    return np.stack(imgs_arr, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T05:29:15.210711Z",
     "start_time": "2020-04-28T05:29:13.027784Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T05:29:17.186101Z",
     "start_time": "2020-04-28T05:29:15.961909Z"
    }
   },
   "outputs": [],
   "source": [
    "# ada 2 cara load model, jika cara pertama berhasil maka bisa lasngusng di lanjutkan ke fungsi prediksi\n",
    "\n",
    "MODEL_PATH = 'model/medium_project/model.h5'\n",
    "model = load_model(MODEL_PATH,compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T05:53:18.906930Z",
     "start_time": "2020-04-28T05:53:18.862643Z"
    }
   },
   "outputs": [],
   "source": [
    "# read image\n",
    "im = Image.open('contoh_prediksi.jpg')\n",
    "X = preprocess(im,input_size)\n",
    "X = reshape([X])\n",
    "y = model.predict(X)\n",
    "\n",
    "print( labels[np.argmax(y)], np.max(y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T05:55:25.943020Z",
     "start_time": "2020-04-28T05:55:25.940623Z"
    }
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T05:55:31.926225Z",
     "start_time": "2020-04-28T05:55:31.923969Z"
    }
   },
   "outputs": [],
   "source": [
    "print( labels[np.argmax(y)], np.max(y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T05:38:01.137699Z",
     "start_time": "2020-04-28T05:38:01.057364Z"
    }
   },
   "outputs": [],
   "source": [
    "# read image\n",
    "im = Image.open('dataset/train/dandelion/2522454811_f87af57d8b.jpg')\n",
    "X = preprocess(im,input_size)\n",
    "X = reshape([X])\n",
    "y = model.predict(X)\n",
    "\n",
    "print( labels[np.argmax(y)], np.max(y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.applications import EfficientNetB2, EfficientNetB0\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (260, 260, 3)\n",
    "base_model = EfficientNetB2(include_top=True, weights='imagenet', input_shape=input_shape)\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "# Melihat layer terakhir yang memungkinkan dihasilkan output\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.summary()\n",
    "\n",
    "base_model = EfficientNetB0(include_top=True, weights='imagenet', input_shape=(224, 224, 3))\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('top_bn').output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "# x = base_model.output\n",
    "# x = layers.Flatten()(x)\n",
    "\n",
    "# model = Model(inputs=base_model.input, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "print('Compiling Model.......')\n",
    "model.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fungsi untuk membuka gambar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "input_size = model.input_shape[1:3]\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image(path):\n",
    "    im = Image.open(path)\n",
    "    X = preprocess(im, model.input_shape[1:3])\n",
    "    X = reshape([X])\n",
    "    return X\n",
    "\n",
    "def preprocess(img,input_size):\n",
    "    nimg = img.convert('RGB').resize(input_size, resample= 0)\n",
    "    img_arr = (np.array(nimg))/255\n",
    "    return img_arr\n",
    "\n",
    "def reshape(imgs_arr):\n",
    "    return np.stack(imgs_arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = open_image(\"contoh_prediksi.jpg\")\n",
    "result = model.predict(X)[0]\n",
    "result[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scann directory\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "mypath= 'flowers/'\n",
    "\n",
    "file_name = []\n",
    "tag = []\n",
    "full_path = []\n",
    "for path, subdirs, files in os.walk(mypath):\n",
    "    for name in files:\n",
    "        full_path.append(os.path.join(path, name).replace(\"\\\\\",\"/\")) \n",
    "        tag.append(path.split('/')[-1])        \n",
    "        file_name.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"path\":full_path,'file_name':file_name,\"tag\":tag})\n",
    "list_img_path = df['path'].tolist()\n",
    "\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array_resut = []\n",
    "for path in tqdm(list_img_path):\n",
    "    X = open_image(path)\n",
    "    res = model.predict(X)[0]\n",
    "    img_array_resut.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['features'] = img_array_resut\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n",
    "\n",
    "f = len(img_array_resut[0])\n",
    "t = AnnoyIndex(f, 'euclidean')\n",
    "\n",
    "print(f\"Number of features {f}\")\n",
    "print(\"Append the item vectors\")\n",
    "i = 0 \n",
    "for v in tqdm(img_array_resut):\n",
    "    t.add_item(i, v)\n",
    "    i += 1\n",
    "\n",
    "print(\"Building the tree\")\n",
    "t.build(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_idx = 1231\n",
    "similar_result = t.get_nns_by_item(image_idx, n=10, include_distances=True)\n",
    "similar_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = list_img_path[image_idx]\n",
    "im = Image.open(path)\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "columns = 4\n",
    "rows = 4\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "for idx in similar_result[0][1:]:\n",
    "    path = list_img_path[idx]\n",
    "    im = Image.open(path)\n",
    "\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(im)\n",
    "    i += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
